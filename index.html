<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
Design by TEMPLATED
http://templated.co
Released for free under the Creative Commons Attribution License

Name       : GrassyGreen 
Description: A two-column, fixed-width design with dark color scheme.
Version    : 1.0
Released   : 20140310

-->
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Solving Mazes in Minecraft Using Deep Reinforcement Learning</title>
<meta name="keywords" content="" />
<meta name="description" content="" />
<link href="http://fonts.googleapis.com/css?family=Raleway:400,200,500,600,700,800,300" rel="stylesheet" />
<link href="default.css" rel="stylesheet" type="text/css" media="all" />
<link href="fonts.css" rel="stylesheet" type="text/css" media="all" />
<!--[if IE 6]>
<link href="default_ie6.css" rel="stylesheet" type="text/css" />
<![endif]-->
</head>
<body>
<div id="wrapper">
	<div id="menu-wrapper">
		<div id="menu" class="container">
			<ul>
				<li class="current_page_item"><a href="#">Proposal</a></li>
				<li><a href="progress.html">Progress Report</a></li>
				<li><a href="final.html">Final Report</a></li>
				<li><a href="about.html">About</a></li>
			</ul>
		</div>
		<!-- end #menu --> 
	<div id="header-wrapper">
		<div id="header" class="container">
			<div id="logo" style = "height: unset; width: unset;">
				<h1><a href="#">Solving Mazes in Minecraft Using Deep Reinforcement Learning</a></h1>
				<p>Project for UCI CS175: Project in Artificial Intelligence (Winter 2020)</p>
			</div>
		</div>
	</div>
	</div>
	<div id="banner" style = "background: url(images/minecraftbanner.png) no-repeat center;background-size: cover;"></div>
	<div id="page" class="container">
		<div id="content">
			<div class="title">
				<h2>Summary of the Project</h2>
				<span class="byline">The main idea behind our project</span> 
			</div>
			<p>    The overall goal of our project is to develop and train an agent that can guide our Minecraft user from the beginning of a maze to the end. The main idea is to create an agent that is capable of learning and familiarizing itself in different environments and then being able to make the best decision at every move to find the best overall route. Given the style of our project, our main duty will be to continually feed the agent different mazes of varying difficulty, to reinforce its ability to make decisions. Simple mazes may just be mazes that contain one clear route from start to end, and the agent has to learn what directions to move in order to reach the end. As for more difficult mazes, the environment may be more dynamic and have obstacles that will require the agent to make more complicated decisions on how to tackle the obstacles. The agent will decide between simple actions such as moving forward/backward as well as complicated actions like digging or building to reach the end of the maze. Our main goal will be to get this agent up and working, and from there we will work on improving its effectiveness and efficiency. In regards to input and output, we will be feeding the agent its immediate surroundings which will include what obstacles stand in its way, what sort of materials the surroundings are composed of, and further information such as if the surroundings are appropriate to build or dig on. The output will be a metric of success that we will use to rank how close our Minecraft character is to the end of the maze.<br><br></p>


			<div class="title">
				<h2>Evaluation Plan</h2>
				<span class="byline">How we will evaluate the success of our project</span> 
			</div>
			<p>In order to evaluate the performance of the agent, we will be using a metric of success and failure where as the agent fails, the metric will decrease and when the agent succeeds, the metric will increase. The metric we will be using will be both a distance based heuristic and a multiplier. The euclidean distance between the final position of the agent and the target block will be our distance based heuristic. That metric will also be summed with a cost heuristic of each action the agent takes. Combied, we will also give the agent a score multiplier of whether the agent reached the target or not. As a base, we should expect the agent to slowly reach a neutral score of say zero, and slowly improve towards a 1. Whenever the agent fails, the metric will decline towards say -1.<br><br>

			 Some qualitative verifications we can make are to visual observe whether the agent is getting better over time and printing metadata of each epoch to the terminal and observe if there are any improvements. We will first begin by navigating through a simple maze where the agent must simply walk forward to reach the goal. From there we will create more intricate and difficult mazes using a larger variety of actions to reach different states.<br><br>


			 One highly ambitious goal would be to have the agent use all types of movement commands in minecraft to be able to reach the target including mining, building, and jumping.<br><br>

			</p>

			<div class="title">
				<h2>Goals</h2>
				<span class="byline">Our three goals and milestones</span> 
			</div>
			<p>The minimum goal will be to accomplish simple movement from the start point to the end point in a basic maze (small in size and not difficult to navigate). The first milestone is using only back and forth movement to get to the end point in the basic maze. The second milestone will be to use a combination of front, back, left, and right movement to navigate to the end point.<br><br>


			The realistic goal will be to add in jumping/digging actions in order for the agent to achieve its goal. While most of the maze walls will be made of bedrock (undestroyable), some walls will have dirt patches for the agent to dig with a shovel to “cut through” paths and create a shorter and better paths. The first milestone will be to teach the agent to learn to dig when able. The second milestone will be to teach the agent to dig and make paths when it is more efficient to do so, rather than exploring and using a longer path.<br><br>


			The ambitious goal will be to allow the agent to build in the maze to help it reach the end point. The agent should learn whether it would be more efficient to build and jump over a wall rather than going around the maze walls. For this goal, its milestone would be to build to jump over a wall or dig under the wall rather than going around the wall to get to the end point.<br><br>
			</p>

			<div class="title">
				<h2>Appointment with the Instructor</h2>
			</div>
			<p>Thursday, January 30th, 1:45 PM 
			</p>
		</div>

		<div id="sidebar">
			<div class="box2">
			</div>
		</div>
	</div>
</div>
	
<div id="copyright" class="container">
	<p>&copy; Untitled. All rights reserved. | Photos by <a href="http://fotogrph.com/">Fotogrph</a> | Design by <a href="http://templated.co" rel="nofollow">TEMPLATED</a>.</p>
</div>
</body>
</html>
